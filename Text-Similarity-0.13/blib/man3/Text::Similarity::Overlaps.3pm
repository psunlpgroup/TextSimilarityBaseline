.\" Automatically generated by Pod::Man 2.27 (Pod::Simple 3.28)
.\"
.\" Standard preamble:
.\" ========================================================================
.de Sp \" Vertical space (when we can't use .PP)
.if t .sp .5v
.if n .sp
..
.de Vb \" Begin verbatim text
.ft CW
.nf
.ne \\$1
..
.de Ve \" End verbatim text
.ft R
.fi
..
.\" Set up some character translations and predefined strings.  \*(-- will
.\" give an unbreakable dash, \*(PI will give pi, \*(L" will give a left
.\" double quote, and \*(R" will give a right double quote.  \*(C+ will
.\" give a nicer C++.  Capital omega is used to do unbreakable dashes and
.\" therefore won't be available.  \*(C` and \*(C' expand to `' in nroff,
.\" nothing in troff, for use with C<>.
.tr \(*W-
.ds C+ C\v'-.1v'\h'-1p'\s-2+\h'-1p'+\s0\v'.1v'\h'-1p'
.ie n \{\
.    ds -- \(*W-
.    ds PI pi
.    if (\n(.H=4u)&(1m=24u) .ds -- \(*W\h'-12u'\(*W\h'-12u'-\" diablo 10 pitch
.    if (\n(.H=4u)&(1m=20u) .ds -- \(*W\h'-12u'\(*W\h'-8u'-\"  diablo 12 pitch
.    ds L" ""
.    ds R" ""
.    ds C` ""
.    ds C' ""
'br\}
.el\{\
.    ds -- \|\(em\|
.    ds PI \(*p
.    ds L" ``
.    ds R" ''
.    ds C`
.    ds C'
'br\}
.\"
.\" Escape single quotes in literal strings from groff's Unicode transform.
.ie \n(.g .ds Aq \(aq
.el       .ds Aq '
.\"
.\" If the F register is turned on, we'll generate index entries on stderr for
.\" titles (.TH), headers (.SH), subsections (.SS), items (.Ip), and index
.\" entries marked with X<> in POD.  Of course, you'll have to process the
.\" output yourself in some meaningful fashion.
.\"
.\" Avoid warning from groff about undefined register 'F'.
.de IX
..
.nr rF 0
.if \n(.g .if rF .nr rF 1
.if (\n(rF:(\n(.g==0)) \{
.    if \nF \{
.        de IX
.        tm Index:\\$1\t\\n%\t"\\$2"
..
.        if !\nF==2 \{
.            nr % 0
.            nr F 2
.        \}
.    \}
.\}
.rr rF
.\"
.\" Accent mark definitions (@(#)ms.acc 1.5 88/02/08 SMI; from UCB 4.2).
.\" Fear.  Run.  Save yourself.  No user-serviceable parts.
.    \" fudge factors for nroff and troff
.if n \{\
.    ds #H 0
.    ds #V .8m
.    ds #F .3m
.    ds #[ \f1
.    ds #] \fP
.\}
.if t \{\
.    ds #H ((1u-(\\\\n(.fu%2u))*.13m)
.    ds #V .6m
.    ds #F 0
.    ds #[ \&
.    ds #] \&
.\}
.    \" simple accents for nroff and troff
.if n \{\
.    ds ' \&
.    ds ` \&
.    ds ^ \&
.    ds , \&
.    ds ~ ~
.    ds /
.\}
.if t \{\
.    ds ' \\k:\h'-(\\n(.wu*8/10-\*(#H)'\'\h"|\\n:u"
.    ds ` \\k:\h'-(\\n(.wu*8/10-\*(#H)'\`\h'|\\n:u'
.    ds ^ \\k:\h'-(\\n(.wu*10/11-\*(#H)'^\h'|\\n:u'
.    ds , \\k:\h'-(\\n(.wu*8/10)',\h'|\\n:u'
.    ds ~ \\k:\h'-(\\n(.wu-\*(#H-.1m)'~\h'|\\n:u'
.    ds / \\k:\h'-(\\n(.wu*8/10-\*(#H)'\z\(sl\h'|\\n:u'
.\}
.    \" troff and (daisy-wheel) nroff accents
.ds : \\k:\h'-(\\n(.wu*8/10-\*(#H+.1m+\*(#F)'\v'-\*(#V'\z.\h'.2m+\*(#F'.\h'|\\n:u'\v'\*(#V'
.ds 8 \h'\*(#H'\(*b\h'-\*(#H'
.ds o \\k:\h'-(\\n(.wu+\w'\(de'u-\*(#H)/2u'\v'-.3n'\*(#[\z\(de\v'.3n'\h'|\\n:u'\*(#]
.ds d- \h'\*(#H'\(pd\h'-\w'~'u'\v'-.25m'\f2\(hy\fP\v'.25m'\h'-\*(#H'
.ds D- D\\k:\h'-\w'D'u'\v'-.11m'\z\(hy\v'.11m'\h'|\\n:u'
.ds th \*(#[\v'.3m'\s+1I\s-1\v'-.3m'\h'-(\w'I'u*2/3)'\s-1o\s+1\*(#]
.ds Th \*(#[\s+2I\s-2\h'-\w'I'u*3/5'\v'-.3m'o\v'.3m'\*(#]
.ds ae a\h'-(\w'a'u*4/10)'e
.ds Ae A\h'-(\w'A'u*4/10)'E
.    \" corrections for vroff
.if v .ds ~ \\k:\h'-(\\n(.wu*9/10-\*(#H)'\s-2\u~\d\s+2\h'|\\n:u'
.if v .ds ^ \\k:\h'-(\\n(.wu*10/11-\*(#H)'\v'-.4m'^\v'.4m'\h'|\\n:u'
.    \" for low resolution devices (crt and lpr)
.if \n(.H>23 .if \n(.V>19 \
\{\
.    ds : e
.    ds 8 ss
.    ds o a
.    ds d- d\h'-1'\(ga
.    ds D- D\h'-1'\(hy
.    ds th \o'bp'
.    ds Th \o'LP'
.    ds ae ae
.    ds Ae AE
.\}
.rm #[ #] #H #V #F C
.\" ========================================================================
.\"
.IX Title "Text::Similarity::Overlaps 3"
.TH Text::Similarity::Overlaps 3 "2015-10-08" "perl v5.18.4" "User Contributed Perl Documentation"
.\" For nroff, turn off justification.  Always turn off hyphenation; it makes
.\" way too many mistakes in technical documents.
.if n .ad l
.nh
.SH "NAME"
Text::Similarity::Overlaps \- Score the Overlaps Found Between Two Strings Based on Literal Text Matching
.SH "SYNOPSIS"
.IX Header "SYNOPSIS"
.Vb 4
\&          # you can measure the similarity between two input strings : 
\&          # if you don\*(Aqt normalize the score, you get the number of matching words
\&          # if you normalize, you get a score between 0 and 1 that is scaled based
\&          # on the length of the strings
\&
\&          use Text::Similarity::Overlaps;
\& 
\&          # my %options = (\*(Aqnormalize\*(Aq => 1, \*(Aqverbose\*(Aq => 1);
\&          my %options = (\*(Aqnormalize\*(Aq => 0, \*(Aqverbose\*(Aq => 0);
\&          my $mod = Text::Similarity::Overlaps\->new (\e%options);
\&          defined $mod or die "Construction of Text::Similarity::Overlaps failed";
\&
\&          my $string1 = \*(Aqthis is a test for getSimilarityStrings\*(Aq;
\&          my $string2 = \*(Aqwe can test getSimilarityStrings this day\*(Aq;
\&
\&          my $score = $mod\->getSimilarityStrings ($string1, $string2);
\&          print "There are $score overlapping words between string1 and string2\en";
\&
\&          # you may want to measure the similarity of a document
\&          # sentence by sentence \- the below example shows you
\&          # how \- suppose you have two text files file1.txt and
\&          # file2.txt \- each having the same number of sentences.
\&          # convert those files into multiple files, where each
\&          # sentence from each file is in a separate file. 
\&
\&          # if file1.txt and file3.txt each have three sentences, 
\&          # filex.txt will become sentx1.txt sentx2.txt sentx3.txt
\&
\&          # this just calls getSimilarity( ) for each pair of sentences
\&
\&          use Text::Similarity::Overlaps;
\&          my %options = (\*(Aqnormalize\*(Aq => 1, \*(Aqverbose\*(Aq =>1, 
\&                                        \*(Aqstoplist\*(Aq => \*(Aqstoplist.txt\*(Aq);
\&          my $mod = Text::Similarity::Overlaps\->new (\e%options);
\&          defined $mod or die "Construction of Text::Similarity::Overlaps failed";
\&
\&          @file1s = qw / sent11.txt sent12.txt sent13.txt /;
\&          @file2s = qw / sent21.txt sent22.txt sent23.txt /;
\&
\&          # assumes that both documents have same number of sentences 
\&
\&          for ($i=0; $i <= $#file1s; $i++) {
\&                  my $score = $mod\->getSimilarity ($file1s[$i], $file2s[$i]);
\&                  print "The similarity of $file1s[$i] and $file2s[$i] is : $score\en";
\&          }
\&
\&          my $score = $mod\->getSimilarity (\*(Aqfile1.txt\*(Aq, \*(Aqfile2.txt\*(Aq);
\&          print "The similarity of the two files is : $score\en";
.Ve
.SH "DESCRIPTION"
.IX Header "DESCRIPTION"
This module computes the similarity of two text documents or strings by 
searching for  literal word token overlaps. This just means that it 
determines how many word tokens are are identical between the two 
strings. Various scores are computed based on the number of shared 
words, and the length of the strings.
.PP
At present similarity measurements are made between entire files or  
strings, and  finer granularity is not supported. Files are treated as 
one long input string, so overlaps can be found across sentence and 
paragraph boundaries.
.PP
Files are first converted into strings by \fIgetSimilarity()\fR, then 
\&\fIgetSimilarityStrings()\fR does the actual processing. It counts the number 
of overlaps (matching words) and finds the longest common subsequences 
(phrases) between the two strings. However, most of the measures except 
for lesk do not use the information about phrasal matches.
.PP
Text::Similarity::Overlaps returns the F\-measure, which is a normalized 
value between 0 and 1. Normalization can be turned off by specifying 
\&\-\-no\-normalize, in which case the raw_score is returned, which is simply 
the number of words that overlap between the two strings.
.PP
In addition, Overlaps returns the cosine, E\-measure, precision, recall, 
Dice coefficient, and Lesk scores in the allScores table.
.PP
.Vb 8
\&     precision = raw_score / length_file_2
\&     recall = raw_score / length_file_1
\&     F\-measure = 2 * precision * recall / (precision + recall)
\&     Dice = 2 * raw_score / (sum of string lengths)
\&     E\-measure = 1 \- F\-measure
\&     Cosine = raw_score / sqrt (precision + recall)
\&     Lesk = sum of the squares of the length of phrasal matches  
\&         (normalized by dividing by the product of the string lengths)
.Ve
.PP
The raw_score is simply the number of matching words between the two
inputs, without respect to their order. Note that matches are literal 
and must be exact, so 'cat' and 'cats' do not match. This corresponds to 
the idea of the intersection between the two strings.
.PP
None of these measures (except lesk) considers the order of the matches. 
In those cases 'jim bit the dog' and 'the dog bit jim' are considered 
exact matches and will attain the highest possible matching score, 
which would be a raw_score of 4 if not normalized and 1 if the score is 
normalized (which would result in the f\-measure being returned).
.PP
lesk is different in that it looks for phrasal matches and scores them 
more highly. The lesk measure is based on the measure of the same name 
included in WordNet::Similarity. There it is used to match the 
overlapping text found in the gloss entries of the lexical database / 
dictionary WordNet in order to measure semantic relatedness.
.PP
The lesk measure finds the length of all the overlaps and squares them. 
It then sums those scores, and if the score is normalized divides them 
by the product of the lengths of the strings. For example:
.PP
.Vb 2
\&        the dog bit jim
\&        jim bit the dog
.Ve
.PP
The raw_score is 4, since the two strings are made up of identical 
words (just in different orders). The F\-measure is equal to 1, as are 
the Cosine, and the Dice Coefficient. In fact, the F\-Measure and the 
Dice Coefficient are always equivalent, but both are presented since 
some users may be more familiar with one formulation versus the other.
.PP
The raw_lesk score is 2^2 + 1 + 1 = 6, because 'the dog' is a phrasal 
match between the strings and thus contributes it's length squared to 
the raw_lesk score. The normalized lesk score is 0.375, which is 6 / 
(4 * 4), or the raw_lesk score divided by the product of the lengths of 
the two strings. Note that the normalized lesk score has a maximum value 
of 1, since if there are n words in the two strings, then their maximum 
overlap is n words, which receives a raw_lesk score of n^2, which is 
the divided by the product of the string lengths, which is again n^2..
.PP
There is some cleaning of text performed automatically, which includes
removal of most punctuation except embedded apostrophes and
underscores. All text is made lower case. This occurs both for file and
string input.
.SH "SEE ALSO"
.IX Header "SEE ALSO"
<http://text\-similarity.sourceforge.net>
.SH "AUTHOR"
.IX Header "AUTHOR"
.Vb 2
\& Ted Pedersen, University of Minnesota, Duluth
\& tpederse at d.umn.edu
\&
\& Jason Michelizzi
.Ve
.PP
Last modified by : 
\&\f(CW$Id:\fR Overlaps.pm,v 1.6 2015/10/08 13:22:13 tpederse Exp $
.SH "COPYRIGHT AND LICENSE"
.IX Header "COPYRIGHT AND LICENSE"
Copyright (C) 2004\-2008 by Jason Michelizzi and Ted Pedersen
.PP
This program is free software; you can redistribute it and/or modify
it under the terms of the \s-1GNU\s0 General Public License as published by
the Free Software Foundation; either version 2 of the License, or
(at your option) any later version.
.PP
This program is distributed in the hope that it will be useful,
but \s-1WITHOUT ANY WARRANTY\s0; without even the implied warranty of
\&\s-1MERCHANTABILITY\s0 or \s-1FITNESS FOR A PARTICULAR PURPOSE. \s0 See the
\&\s-1GNU\s0 General Public License for more details.
.PP
You should have received a copy of the \s-1GNU\s0 General Public License
along with this program; if not, write to the Free Software
Foundation, Inc., 59 Temple Place, Suite 330, Boston, \s-1MA  02111\-1307  USA\s0
